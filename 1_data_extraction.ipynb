{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification - Data Extraction\n",
    "## Extract text from Word and PDF documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import zipfile\n",
    "# import warnings\n",
    "\n",
    "# import pandas as pd\n",
    "# import docx\n",
    "# import PyPDF2\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # =============================\n",
    "# # 1. UNZIP THE DATASET\n",
    "# # =============================\n",
    "\n",
    "# # Path to your ZIP file\n",
    "# # If you're running locally and the zip is in the same folder as your script/notebook:\n",
    "# # zip_path = \"P608-Dataset.zip\"\n",
    "# zip_path = \"P608-Dataset.zip\"   # <-- change this if needed\n",
    "\n",
    "# # Where to extract\n",
    "# extract_to = \".\"   # current directory, or give a folder path like \"data\"\n",
    "\n",
    "# # Extract the zip\n",
    "# with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "#     zf.extractall(extract_to)\n",
    "\n",
    "# print(\"Zip extracted successfully!\")\n",
    "\n",
    "# # After extraction, we expect something like: ./P608-Dataset/Resumes_Docx/...\n",
    "# base_folder = os.path.join(extract_to, \"P608-Dataset\", \"Resumes_Docx\")\n",
    "\n",
    "# print(\"Base folder for resumes:\", base_folder)\n",
    "# print(\"Subfolders:\", os.listdir(base_folder))\n",
    "\n",
    "\n",
    "# # =============================\n",
    "# # 2. HELPER FUNCTIONS\n",
    "# # =============================\n",
    "\n",
    "# def extract_text_from_docx(file_path):\n",
    "#     \"\"\"Extract text from Word document (.docx)\"\"\"\n",
    "#     try:\n",
    "#         doc = docx.Document(file_path)\n",
    "#         text = '\\n'.join([para.text for para in doc.paragraphs])\n",
    "#         return text\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file_path}: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "\n",
    "# def extract_text_from_pdf(file_path):\n",
    "#     \"\"\"Extract text from PDF document\"\"\"\n",
    "#     try:\n",
    "#         with open(file_path, 'rb') as file:\n",
    "#             pdf_reader = PyPDF2.PdfReader(file)\n",
    "#             text = ''\n",
    "#             for page in pdf_reader.pages:\n",
    "#                 page_text = page.extract_text()\n",
    "#                 if page_text:\n",
    "#                     text += page_text\n",
    "#         return text\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error reading {file_path}: {e}\")\n",
    "#         return \"\"\n",
    "\n",
    "\n",
    "# # =============================\n",
    "# # 3. MAIN LOADER FUNCTION\n",
    "# # =============================\n",
    "\n",
    "# def load_documents(base_path):\n",
    "#     \"\"\"\n",
    "#     Load all documents from category folders and create a dataset.\n",
    "#     base_path -> folder that contains 'Peoplesoft', 'React Developer', etc.\n",
    "#     \"\"\"\n",
    "#     data = []\n",
    "    \n",
    "#     # Map folder names to category labels\n",
    "#     categories = {\n",
    "#         'Peoplesoft': 'Peoplesoft',\n",
    "#         'Peoplesoft Resume': 'Peoplesoft',\n",
    "#         'React Developer': 'React Developer',\n",
    "#         'SQL Developer': 'SQL Developer',\n",
    "#         'workday': 'Workday'\n",
    "#     }\n",
    "    \n",
    "#     for folder_name, category in categories.items():\n",
    "#         folder_path = os.path.join(base_path, folder_name)\n",
    "        \n",
    "#         if not os.path.exists(folder_path):\n",
    "#             print(f\"Folder not found, skipping: {folder_path}\")\n",
    "#             continue\n",
    "            \n",
    "#         print(f\"\\nProcessing folder: {folder_name} -> category: {category}\")\n",
    "        \n",
    "#         for filename in os.listdir(folder_path):\n",
    "#             file_path = os.path.join(folder_path, filename)\n",
    "            \n",
    "#             # Skip if it's a directory\n",
    "#             if os.path.isdir(file_path):\n",
    "#                 continue\n",
    "            \n",
    "#             # Read text based on file extension\n",
    "#             if filename.lower().endswith(('.docx', '.doc')):\n",
    "#                 text = extract_text_from_docx(file_path)\n",
    "#             elif filename.lower().endswith('.pdf'):\n",
    "#                 text = extract_text_from_pdf(file_path)\n",
    "#             else:\n",
    "#                 # Skip other file types\n",
    "#                 print(f\"Skipping unsupported file: {file_path}\")\n",
    "#                 continue\n",
    "            \n",
    "#             # Only add non-empty text\n",
    "#             if text.strip():\n",
    "#                 data.append({\n",
    "#                     'filename': filename,\n",
    "#                     'category': category,\n",
    "#                     'text': text,\n",
    "#                     'text_length': len(text)\n",
    "#                 })\n",
    "#             else:\n",
    "#                 print(f\"No text extracted from: {file_path}\")\n",
    "    \n",
    "#     # Convert to DataFrame\n",
    "#     df = pd.DataFrame(data)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# # =============================\n",
    "# # 4. RUN EVERYTHING\n",
    "# # =============================\n",
    "\n",
    "# df = load_documents(base_folder)\n",
    "\n",
    "# print(\"\\nSample rows:\")\n",
    "# print(df.head())\n",
    "\n",
    "# print(\"\\nTotal resumes loaded:\", len(df))\n",
    "\n",
    "# # (Optional) Save to CSV to reuse later\n",
    "# df.to_csv(\"resumes_dataset.csv\", index=False)\n",
    "# print(\"\\nSaved dataset to 'resumes_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T05:44:57.202955Z",
     "iopub.status.busy": "2025-11-26T05:44:57.201954Z",
     "iopub.status.idle": "2025-11-26T05:44:58.572391Z",
     "shell.execute_reply": "2025-11-26T05:44:58.571359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanch\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from docx import Document      # from python-docx\n",
    "import PyPDF2\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ---------- Helpers to extract text ----------\n",
    "\n",
    "def extract_text_from_docx_file(file_obj):\n",
    "    \"\"\"\n",
    "    Extract text from a DOCX file stored inside a ZIP.\n",
    "    file_obj is a file-like object (from z.open()).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = Document(file_obj)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading DOCX: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def extract_text_from_pdf_file(file_obj):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file stored inside a ZIP.\n",
    "    file_obj is a file-like object (from z.open()).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = PyPDF2.PdfReader(file_obj)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# ---------- Main loader from ZIP ----------\n",
    "\n",
    "def load_documents_from_zip(zip_path='P608-Dataset.zip'):\n",
    "    \"\"\"\n",
    "    Load all DOCX/PDF resumes from inside the ZIP and\n",
    "    return them as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # Map folder names to category labels\n",
    "    categories = {\n",
    "        'Peoplesoft': 'Peoplesoft',\n",
    "        'Peoplesoft Resume': 'Peoplesoft',\n",
    "        'React Developer': 'React Developer',\n",
    "        'SQL Developer': 'SQL Developer',\n",
    "        'workday': 'Workday'\n",
    "    }\n",
    "\n",
    "    data = []\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "        for file_name in z.namelist():\n",
    "            # Skip folders\n",
    "            if file_name.endswith('/'):\n",
    "                continue\n",
    "\n",
    "            # We only care about DOCX and PDF\n",
    "            lower_name = file_name.lower()\n",
    "            if not (lower_name.endswith('.docx') or lower_name.endswith('.pdf')):\n",
    "                continue\n",
    "\n",
    "            # Find which folder/category this file belongs to\n",
    "            parts = file_name.split('/')\n",
    "            folder_name = None\n",
    "            for part in parts:\n",
    "                if part in categories:\n",
    "                    folder_name = part\n",
    "                    break\n",
    "\n",
    "            if folder_name is None:\n",
    "                # File not in any of our category folders\n",
    "                continue\n",
    "\n",
    "            category = categories[folder_name]\n",
    "\n",
    "            # Read file content from inside ZIP\n",
    "            with z.open(file_name) as f:\n",
    "                if lower_name.endswith('.docx'):\n",
    "                    text = extract_text_from_docx_file(f)\n",
    "                else:  # PDF\n",
    "                    text = extract_text_from_pdf_file(f)\n",
    "\n",
    "            # Skip completely empty text\n",
    "            if text and text.strip():\n",
    "                data.append({\n",
    "                    'filename': file_name,\n",
    "                    'category': category,\n",
    "                    'text': text,\n",
    "                    'text_length': len(text)\n",
    "                })\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-docx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading DOCX: \"no relationship of type 'http://schemas.openxmlformats.org/officeDocument/2006/relationships/officeDocument' in collection\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PdfReader stream/file object is not in binary mode. It may not be read correctly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 53\n",
      "\n",
      "Category distribution:\n",
      "category\n",
      "React Developer    21\n",
      "SQL Developer      11\n",
      "Workday            11\n",
      "Peoplesoft         10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ---------- Run the loader & show summary ----------\n",
    "\n",
    "df = load_documents_from_zip('P608-Dataset.zip')\n",
    "\n",
    "print(f\"Total documents loaded: {len(df)}\")\n",
    "print(\"\\nCategory distribution:\")\n",
    "if not df.empty:\n",
    "    print(df['category'].value_counts())\n",
    "else:\n",
    "    print(\"No documents found. Check ZIP structure or category folder names.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...</td>\n",
       "      <td>Peoplesoft</td>\n",
       "      <td>Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...</td>\n",
       "      <td>7256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...</td>\n",
       "      <td>Peoplesoft</td>\n",
       "      <td>Murali\\n\\nExperience Summary \\n\\nI have 6 year...</td>\n",
       "      <td>3981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...</td>\n",
       "      <td>Peoplesoft</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPROFILE SUMMARY\\n\\...</td>\n",
       "      <td>3646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...</td>\n",
       "      <td>Peoplesoft</td>\n",
       "      <td>PeopleSoft Admin\\nVARKALA VIKAS\\n\\nCareer Obj...</td>\n",
       "      <td>7265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...</td>\n",
       "      <td>Peoplesoft</td>\n",
       "      <td>PeopleSoft Administration\\n \\nVivekanand Sayan...</td>\n",
       "      <td>15339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    category  \\\n",
       "0  P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...  Peoplesoft   \n",
       "1  P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...  Peoplesoft   \n",
       "2  P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...  Peoplesoft   \n",
       "3  P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...  Peoplesoft   \n",
       "4  P608-Dataset/Resumes_Docx/Peoplesoft Resume/Pe...  Peoplesoft   \n",
       "\n",
       "                                                text  text_length  \n",
       "0    Anubhav Kumar Singh\\t\\t\\n\\n  To work in a gl...         7256  \n",
       "1  Murali\\n\\nExperience Summary \\n\\nI have 6 year...         3981  \n",
       "2  \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPROFILE SUMMARY\\n\\...         3646  \n",
       "3   PeopleSoft Admin\\nVARKALA VIKAS\\n\\nCareer Obj...         7265  \n",
       "4  PeopleSoft Administration\\n \\nVivekanand Sayan...        15339  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data saved to extracted_documents.csv\n"
     ]
    }
   ],
   "source": [
    "# Optional: save to CSV\n",
    "df.to_csv('extracted_documents.csv', index=False)\n",
    "print(\"\\nData saved to extracted_documents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
